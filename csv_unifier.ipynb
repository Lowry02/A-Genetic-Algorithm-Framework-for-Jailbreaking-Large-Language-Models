{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.Logger import Logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = \"./log/llama3.0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = os.listdir(log_folder)\n",
    "rs_files = [file for file in log_files if \"rs\" in file]\n",
    "rs_files = [file for file in rs_files if \"suffix\" not in file]\n",
    "\n",
    "ga_files = [file for file in log_files if \"rs\" not in file]\n",
    "ga_files = [file for file in ga_files if \"suffix\" not in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging execution chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search\n",
    "output_file = \"./log/llama3.0-rs.csv\"\n",
    "runs_list = []\n",
    "suffixes_list = []\n",
    "runs_per_file = 3\n",
    "i = 0\n",
    "\n",
    "def extract_row_info(row):\n",
    "  return row.tolist()\n",
    "\n",
    "for file in rs_files:\n",
    "  run_info = pd.read_csv(log_folder + file)\n",
    "  for run in run_info['run'].unique():\n",
    "    run_info.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  suffixes_file = pd.read_csv(log_folder + file[:-4] + \"-suffix.csv\")\n",
    "  for run in suffixes_file['run'].unique():\n",
    "    suffixes_file.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  runs = run_info.apply(extract_row_info, axis=1)\n",
    "  suffixes = suffixes_file.apply(extract_row_info, axis=1)\n",
    "  runs_list += list(runs)\n",
    "  suffixes_list += list(suffixes)\n",
    "  \n",
    "  i += 1\n",
    "  \n",
    "export_file = pd.DataFrame(runs_list, columns=run_info.columns)\n",
    "export_file['run'] = export_file['run'].astype(int)\n",
    "export_file['iteration'] = export_file['iteration'].astype(int)\n",
    "export_file['sure_generated'] = export_file['sure_generated'].astype(int)\n",
    "export_file.to_csv(output_file, index=False)\n",
    "export_file = pd.DataFrame(suffixes_list, columns=suffixes_file.columns)\n",
    "export_file['run'] = export_file['run'].astype(int)\n",
    "export_file.to_csv(output_file[:-4] + \"-suffix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genetic algorithm\n",
    "output_file = \"./log/llama3.0-ga.csv\"\n",
    "runs_list = []\n",
    "suffixes_list = []\n",
    "runs_per_file = 3\n",
    "i = 0\n",
    "\n",
    "def extract_row_info(row):\n",
    "  return row.tolist()\n",
    "\n",
    "for file in ga_files:\n",
    "  run_info = pd.read_csv(log_folder + file)\n",
    "  for run in run_info['run'].unique():\n",
    "    run_info.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  suffixes_file = pd.read_csv(log_folder + file[:-4] + \"-suffix.csv\")\n",
    "  for run in suffixes_file['run'].unique():\n",
    "    suffixes_file.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  runs = run_info.apply(extract_row_info, axis=1)\n",
    "  suffixes = suffixes_file.apply(extract_row_info, axis=1)\n",
    "  runs_list += list(runs)\n",
    "  suffixes_list += list(suffixes)\n",
    "  \n",
    "  i += 1\n",
    "  \n",
    "export_file = pd.DataFrame(runs_list, columns=run_info.columns)\n",
    "export_file['run'] = export_file['run'].astype(int)\n",
    "export_file['iteration'] = export_file['iteration'].astype(int)\n",
    "export_file['sure_count'] = export_file['sure_count'].astype(int)\n",
    "export_file.to_csv(output_file, index=False)\n",
    "export_file = pd.DataFrame(suffixes_list, columns=suffixes_file.columns)\n",
    "export_file['run'] = export_file['run'].astype(int)\n",
    "export_file.to_csv(output_file[:-4] + \"-suffix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File for transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search\n",
    "i = 0\n",
    "\n",
    "def extract_row_info(row, type):\n",
    "  return [type, int(row['run']), row['fitness'], row['suffix']]\n",
    "\n",
    "for file in rs_files:\n",
    "  run_info = pd.read_csv(log_folder + file)\n",
    "  for run in run_info['run'].unique():\n",
    "    run_info.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "\n",
    "  idx = run_info.groupby('run')['fitness'].idxmax()\n",
    "  runs = run_info.loc[idx].reset_index(drop=True)\n",
    "  \n",
    "  suffixes_file = pd.read_csv(log_folder + file[:-4] + \"-suffix.csv\")\n",
    "  for run in suffixes_file['run'].unique():\n",
    "    suffixes_file.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  runs = pd.merge(runs, suffixes_file, on=['run'])\n",
    "  runs = runs.apply(extract_row_info, axis=1, type=\"rs\")\n",
    "  data += list(runs)\n",
    "  \n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genetic algorithm\n",
    "i = 0\n",
    "\n",
    "def extract_row_info(row, type):\n",
    "  return [type, int(row['run']), row['fitness_max'], row['suffix']]\n",
    "\n",
    "for file in ga_files:\n",
    "  run_info = pd.read_csv(log_folder + file)\n",
    "  for run in run_info['run'].unique():\n",
    "    run_info.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "\n",
    "  idx = run_info.groupby('run')['iteration'].idxmax()\n",
    "  runs = run_info.loc[idx].reset_index(drop=True)\n",
    "  \n",
    "  suffixes_file = pd.read_csv(log_folder + file[:-4] + \"-suffix.csv\")\n",
    "  for run in suffixes_file['run'].unique():\n",
    "    suffixes_file.replace({'run': run}, i * runs_per_file + run, inplace=True)\n",
    "  \n",
    "  runs = pd.merge(runs, suffixes_file, on=['run'])\n",
    "  runs = runs.apply(extract_row_info, axis=1, type=\"ga\")\n",
    "  data += list(runs)\n",
    "  \n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['type', 'run', 'fitness', 'suffix']\n",
    "log = pd.DataFrame(data, columns=columns)\n",
    "log['type'] = log['type'].astype(str)\n",
    "log['run'] = log['run'].astype(int)\n",
    "log['fitness'] = log['fitness'].astype(float)\n",
    "log['suffix'] = log['suffix'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export converted suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Chat import Chat\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def get_suffix(suffix, chat):\n",
    "    suffix = suffix.replace(\"|\", ',')\n",
    "    suffix = ast.literal_eval(suffix)\n",
    "    adv_suffix = chat.detokenize([suffix])\n",
    "    return adv_suffix[0]\n",
    "\n",
    "transferability_info = \"./transferability/llama3.0/self-transferability-info.csv\"\n",
    "output_file  = \"./transferability/llama3.0/self-transferability-converted.csv\"\n",
    "\n",
    "data = pd.read_csv(transferability_info)\n",
    "data['suffix'] = data['suffix'].astype(str)\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "device = 'cuda'\n",
    "quantized = False\n",
    "chat = Chat(model_name, device=device, quantized=quantized)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    suffix = get_suffix(row['suffix'])\n",
    "    data.loc[idx, 'suffix'] = suffix\n",
    "    \n",
    "data.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
